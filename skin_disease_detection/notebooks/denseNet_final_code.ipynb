{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def resize_images(input_dir, output_dir, size=(224, 224)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for dirpath, _, filenames in os.walk(input_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(dirpath, filename)\n",
    "                print(f\"Processing {img_path}\")\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    # Create the corresponding output path\n",
    "                    relative_path = os.path.relpath(dirpath, input_dir)\n",
    "                    output_subdir = os.path.join(output_dir, relative_path)\n",
    "                    if not os.path.exists(output_subdir):\n",
    "                        os.makedirs(output_subdir)\n",
    "                    \n",
    "                    output_path = os.path.join(output_subdir, filename)\n",
    "                    resized_img = cv2.resize(img, size)\n",
    "                    cv2.imwrite(output_path, resized_img)\n",
    "                    print(f\"Saved resized image to {output_path}\")\n",
    "                else:\n",
    "                    print(f\"Error reading image: {img_path}\")\n",
    "\n",
    "# Resize train, validate, and test images\n",
    "resize_images(r'dataset_initial', r'dataset_resized')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Outliers Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def display_images(image_paths, n=5):\n",
    "    \"\"\"\n",
    "    Display up to 'n' images from the given list of image paths.\n",
    "    \"\"\"\n",
    "    for i in range(min(n, len(image_paths))):\n",
    "        img = Image.open(image_paths[i])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def detect_outliers(image_paths, size_threshold=(200, 200), aspect_ratio_range=(0.5, 2.0)):\n",
    "    \"\"\"\n",
    "    Detect outliers based on size and aspect ratio.\n",
    "    Args:\n",
    "        image_paths (list): List of image paths.\n",
    "        size_threshold (tuple): Minimum (width, height) allowed.\n",
    "        aspect_ratio_range (tuple): Min and max aspect ratio (width/height).\n",
    "    \n",
    "    Returns:\n",
    "        valid_paths (list): List of valid image paths.\n",
    "        outlier_paths (list): List of outlier image paths.\n",
    "    \"\"\"\n",
    "    valid_paths = []\n",
    "    outlier_paths = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                width, height = img.size\n",
    "                aspect_ratio = width / height\n",
    "\n",
    "                # Check if the image is within valid size and aspect ratio range\n",
    "                if (\n",
    "                    width >= size_threshold[0]\n",
    "                    and height >= size_threshold[1]\n",
    "                    and aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]\n",
    "                ):\n",
    "                    valid_paths.append(path)\n",
    "                else:\n",
    "                    outlier_paths.append(path)\n",
    "        except (UnidentifiedImageError, IOError):\n",
    "            # Handle corrupted or unopenable images\n",
    "            outlier_paths.append(path)\n",
    "\n",
    "    return valid_paths, outlier_paths\n",
    "\n",
    "def remove_outliers(outlier_paths):\n",
    "    \"\"\"\n",
    "    Remove files listed in outlier_paths.\n",
    "    \"\"\"\n",
    "    for path in outlier_paths:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "            print(f\"Removed outlier: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to remove {path}: {e}\")\n",
    "\n",
    "# Collect all image paths\n",
    "image_paths = []\n",
    "for subdir, dirs, files in os.walk(r'dataset_resized'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        image_paths.append(file_path)\n",
    "\n",
    "# Detect and remove outliers\n",
    "valid_paths, outlier_paths = detect_outliers(image_paths)\n",
    "print(f\"Found {len(outlier_paths)} outliers.\")\n",
    "\n",
    "remove_outliers(outlier_paths)\n",
    "\n",
    "# Display valid images\n",
    "display_images(valid_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Corrupted Files Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def is_image_corrupted(file_path):\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()  # Verifies if the image can be opened\n",
    "        return False\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        return True\n",
    "\n",
    "corrupted_images = []\n",
    "for subdir, dirs, files in os.walk(r'dataset_resized'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        if is_image_corrupted(file_path):\n",
    "            corrupted_images.append(file_path)\n",
    "\n",
    "print(f\"Found {len(corrupted_images)} corrupted images.\")\n",
    "for img_path in corrupted_images:\n",
    "    os.remove(img_path)  # Remove the corrupted image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Duplicates Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "\n",
    "def hash_image(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "image_hashes = {}\n",
    "duplicate_images = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(r'dataset_resized'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        img_hash = hash_image(file_path)\n",
    "        if img_hash in image_hashes:\n",
    "            duplicate_images.append(file_path)\n",
    "        else:\n",
    "            image_hashes[img_hash] = file_path\n",
    "\n",
    "print(f\"Found {len(duplicate_images)} duplicate images.\")\n",
    "for img_path in duplicate_images:\n",
    "    os.remove(img_path)  # Remove the duplicate image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define your source and destination directories\n",
    "source_dir = r'dataset_resized'  # Update this path\n",
    "destination_dir = r'dataset_final'  # Update this path\n",
    "\n",
    "# Create new train, validate, and test folders\n",
    "os.makedirs(os.path.join(destination_dir, 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(destination_dir, 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(destination_dir, 'test'), exist_ok=True)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "validate_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Iterate through each disease subfolder\n",
    "for disease_folder in os.listdir(source_dir):\n",
    "    disease_path = os.path.join(source_dir, disease_folder)\n",
    "    \n",
    "    if os.path.isdir(disease_path):  # Check if it's a folder\n",
    "        images = os.listdir(disease_path)\n",
    "        random.shuffle(images)  # Shuffle the images\n",
    "        \n",
    "        # Calculate split indices\n",
    "        total_images = len(images)\n",
    "        train_count = int(total_images * train_ratio)\n",
    "        validate_count = int(total_images * validate_ratio)\n",
    "        \n",
    "        # Split images\n",
    "        train_images = images[:train_count]\n",
    "        validate_images = images[train_count:train_count + validate_count]\n",
    "        test_images = images[train_count + validate_count:]\n",
    "\n",
    "        # Create subfolders for each category and copy images\n",
    "        for category, image_list in zip(['train', 'val', 'test'], [train_images, validate_images, test_images]):\n",
    "            category_path = os.path.join(destination_dir, category, disease_folder)\n",
    "            os.makedirs(category_path, exist_ok=True)\n",
    "            for image in image_list:\n",
    "                shutil.copy(os.path.join(disease_path, image), category_path)\n",
    "\n",
    "print(\"Images have been organized into train, validate, and test folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define augmentations to apply\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "# Path to the training dataset\n",
    "train_data_path = r'dataset_final\\train'\n",
    "\n",
    "# Target number of images per class\n",
    "target_count = 200\n",
    "\n",
    "# Loop over each class folder in the training directory\n",
    "for class_name in os.listdir(train_data_path):\n",
    "    class_path = os.path.join(train_data_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        # Get list of image files in this class folder\n",
    "        image_files = [f for f in os.listdir(class_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        current_count = len(image_files)\n",
    "\n",
    "        if current_count < target_count:\n",
    "            print(f\"Augmenting class {class_name}: {current_count} -> {target_count}\")\n",
    "            for i in range(target_count - current_count):\n",
    "                # Randomly select an image to augment\n",
    "                img_file = random.choice(image_files)\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "\n",
    "                # Open the image and apply augmentations\n",
    "                img = Image.open(img_path)\n",
    "                augmented_img = augmentations(img)\n",
    "\n",
    "                # Save the augmented image\n",
    "                new_img_name = f\"{class_name}_aug_{i}.jpg\"\n",
    "                new_img_path = os.path.join(class_path, new_img_name)\n",
    "                augmented_img.save(new_img_path)\n",
    "\n",
    "print(\"Augmentation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory relative to the script location\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Construct paths using os.path.join\n",
    "train_dir = os.path.join(base_dir, 'dataset_final', 'train')\n",
    "val_dir = os.path.join(base_dir, 'dataset_final', 'val')\n",
    "\n",
    "# Set device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Number of classes in your dataset\n",
    "num_classes = 43\n",
    "\n",
    "# Data transformations for training and validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(root=train_dir, transform=data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(root=val_dir, transform=data_transforms['val']),\n",
    "}\n",
    "\n",
    "# Create DataLoader\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=32, shuffle=True),\n",
    "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=32, shuffle=False),\n",
    "}\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    test_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "    return test_loss, test_acc, all_preds, all_labels\n",
    "\n",
    "# Train and evaluate the DenseNet model with early stopping and regularization\n",
    "def train_and_evaluate(model, num_epochs=10, patience=3):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Add L2 regularization (weight_decay)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Store loss and accuracy per epoch\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_accuracies.append(epoch_acc)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_accuracies.append(epoch_acc)\n",
    "\n",
    "            # Early stopping: check for validation loss improvement\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    early_stop_counter = 0  # Reset counter if improvement\n",
    "                else:\n",
    "                    early_stop_counter += 1  # Increment if no improvement\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Define the path\n",
    "    model_save_path = os.path.join(base_dir, 'DenseNet_model.pth')\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f'Model saved to {model_save_path}')\n",
    "\n",
    "    return model, best_acc, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Initialize the DenseNet model with Dropout\n",
    "class DenseNetWithDropout(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNetWithDropout, self).__init__()\n",
    "        self.densenet = models.densenet121(weights='DEFAULT')\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # Dropout before final layer\n",
    "            nn.Linear(self.densenet.classifier.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "\n",
    "model = DenseNetWithDropout(num_classes)\n",
    "\n",
    "print(\"\\nTraining DenseNet with early stopping, dropout, and L2 regularization...\")\n",
    "trained_model, accuracy, train_losses, val_losses, train_accuracies, val_accuracies = train_and_evaluate(model)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "test_loss, test_acc, preds, labels = evaluate_model(trained_model, dataloaders['val'], nn.CrossEntropyLoss())\n",
    "print(f'DenseNet Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=image_datasets['val'].classes, columns=image_datasets['val'].classes)\n",
    "\n",
    "# Save the confusion matrix to an Excel file\n",
    "excel_file_path = os.path.join(base_dir, 'confusion_matrix.xlsx')\n",
    "cm_df.to_excel(excel_file_path)\n",
    "\n",
    "print(f\"Confusion matrix saved to {excel_file_path}\")\n",
    "\n",
    "# Plotting Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=image_datasets['val'].classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for DenseNet')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Loss and Accuracy\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, 'bo-', label='Train Loss')\n",
    "plt.plot(epochs, val_losses, 'ro-', label='Val Loss')\n",
    "plt.title('DenseNet Loss per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'ro-', label='Val Accuracy')\n",
    "plt.title('DenseNet Accuracy per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the base directory relative to the script location\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = 43\n",
    "\n",
    "# Define the data transformations for the test set\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset_path = os.path.join(base_dir, \"dataset_final\", \"test\")\n",
    "if not os.path.exists(test_dataset_path):\n",
    "    raise FileNotFoundError(f\"Test dataset path does not exist: {test_dataset_path}\")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dataset_path, transform=test_transform)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the DenseNet model with dropout\n",
    "class DenseNetWithDropout(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNetWithDropout, self).__init__()\n",
    "        self.densenet = models.densenet121(weights='DEFAULT')  # For PyTorch >= 1.12.0\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # Dropout before final layer\n",
    "            nn.Linear(self.densenet.classifier.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "\n",
    "# Initialize the model and load the trained weights\n",
    "model = DenseNetWithDropout(num_classes).to(device)\n",
    "model_path = os.path.join(base_dir, \"DenseNet_model02.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file does not exist: {model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluation function for the test set\n",
    "def evaluate_model(model, dataloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    test_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "    return test_loss, test_acc, all_preds, all_labels\n",
    "\n",
    "# Run evaluation on the test set\n",
    "test_loss, test_acc, preds, labels = evaluate_model(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_df = pd.DataFrame(cm, index=test_dataset.classes, columns=test_dataset.classes)\n",
    "\n",
    "# Save confusion matrix to Excel\n",
    "excel_file_path = os.path.join(base_dir, \"confusion_matrix_test.xlsx\")\n",
    "cm_df.to_excel(excel_file_path)\n",
    "print(f\"Confusion matrix saved to {excel_file_path}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
